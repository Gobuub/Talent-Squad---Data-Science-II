{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbd678b",
   "metadata": {},
   "source": [
    "## Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a data generator\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.15,\n",
    "                            zoom_range=0.1,\n",
    "                            channel_shift_range=10,\n",
    "                            horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['baseball', 'cricket', 'football']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcff53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(datagen, target: str)->None:\n",
    "    '''\n",
    "        This function receives a data generator and target and returns\n",
    "        a number of copies of the same image with different transformations,\n",
    "        to increment the number of images for train our model\n",
    "        \n",
    "        Parameters:\n",
    "            datagen: Object generator with the features to transform the image\n",
    "            target: str\n",
    "    \n",
    "        Returns:\n",
    "            A message of work is done\n",
    "    '''\n",
    "    \n",
    "    # first create a list of the files on the target folder\n",
    "    target_lst = [f'img/train/{target}/' + f for f in os.listdir(f'img/train/{target}/') if isfile(join(f'img/train/{target}/', f))]\n",
    "    # path for save the augmentated data\n",
    "    save_here = f'img/train/{target}/aug'\n",
    "    try:\n",
    "        os.stat(save_here) # if folder exits save on it\n",
    "    except:\n",
    "        os.mkdir(save_here) # if not, create it and save on it\n",
    "    for i in tqdm(range(64)):\n",
    "        # transformation the image\n",
    "        image = np.expand_dims(imread(target_lst[i]), axis=0) \n",
    "        datagen.fit(image)\n",
    "        # makes the augmetation\n",
    "        for x, val in zip(datagen.flow(image,                     # image we choose\n",
    "                                  save_to_dir=save_here,          # the folder on we save the new image \n",
    "                                  save_prefix='aug',               \n",
    "                                  save_format='png'), range(100)): # number of augmented images we want\n",
    "            pass\n",
    "    return 'Augmentation Finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7afe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    augment_data(datagen, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263fe1f5",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/baseball/aug/')):\n",
    "    image = imread('img/train/baseball/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(64,64))\n",
    "    X.append(smallimage)\n",
    "    Y.append(0)\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/cricket/aug/')):\n",
    "    image = imread('img/train/cricket/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(64,64))\n",
    "    X.append(smallimage)\n",
    "    Y.append(1)\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/football/aug/')):\n",
    "    image = imread('img/train/football/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(64,64))\n",
    "    X.append(smallimage)\n",
    "    Y.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_128 = []\n",
    "Y_128 = []\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/baseball/aug/')):\n",
    "    image = imread('img/train/baseball/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(128,128))\n",
    "    X_128.append(smallimage)\n",
    "    Y_128.append(0)\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/cricket/aug/')):\n",
    "    image = imread('img/train/cricket/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(128,128))\n",
    "    X_128.append(smallimage)\n",
    "    Y_128.append(1)\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/football/aug/')):\n",
    "    image = imread('img/train/football/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(128,128))\n",
    "    X_128.append(smallimage)\n",
    "    Y_128.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_32 = []\n",
    "Y_32 = []\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/baseball/aug/')):\n",
    "    image = imread('img/train/baseball/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(32,32))\n",
    "    X_32.append(smallimage)\n",
    "    Y_32.append(0)\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/cricket/aug/')):\n",
    "    image = imread('img/train/cricket/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(32,32))\n",
    "    X_32.append(smallimage)\n",
    "    Y_32.append(1)\n",
    "\n",
    "for file in tqdm(os.listdir('img/train/football/aug/')):\n",
    "    image = imread('img/train/football/aug/'+file)\n",
    "    smallimage = cv2.resize(image,(32,32))\n",
    "    X_32.append(smallimage)\n",
    "    Y_32.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b04506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = np.array(X), np.array(Y)\n",
    "X_128,Y_128 = np.array(X_128), np.array(Y_128)\n",
    "X_32,Y_32 = np.array(X_32), np.array(Y_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c03050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0 # normalize X\n",
    "X_128 = X_128/255.0\n",
    "X_32 = X_32/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X,Y = shuffle(X,Y, random_state=42)\n",
    "\n",
    "X_128,Y_128 = shuffle(X_128,Y_128, random_state=42)\n",
    "\n",
    "X_32, Y_32 = shuffle(X_32,Y_32, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = .2, random_state=42, stratify=Y)\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print(np.unique(y_train,return_counts=True),'values of each class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc77212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_32, X_test_32, y_train_32, y_test_32 = train_test_split(X_32,Y_32, test_size = .2, random_state=42, stratify=Y_32)\n",
    "\n",
    "print(X_train_32.shape); print(X_test_32.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f86d0a",
   "metadata": {},
   "source": [
    "### Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f37842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "import numpy as np\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021662dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train,3)\n",
    "Y_test = np_utils.to_categorical(y_test,3)\n",
    "\n",
    "Y_train_32 = np_utils.to_categorical(y_train_32,3)\n",
    "Y_test_32 = np_utils.to_categorical(y_test_32,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e8976",
   "metadata": {},
   "source": [
    "### Create metric functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4609ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978a680",
   "metadata": {},
   "source": [
    "## Create a convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c815901",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 32\n",
    "img_cols = 32\n",
    "kernel_size = 4 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 3))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 3))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\", f1_m, recall_m, precision_m])\n",
    "history_3 = model.fit(\n",
    "    X_train_32, # Training data\n",
    "    Y_train_32, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=10, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(X_test_32, Y_test_32)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])\n",
    "\n",
    "pd.DataFrame(history_3.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8340bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_32 = []\n",
    "\n",
    "for file in os.listdir('img/test/'):\n",
    "    image = imread('img/test/'+file)\n",
    "    smallimage = cv2.resize(image,(32,32))\n",
    "    test_32.append(smallimage)\n",
    "\n",
    "test_32 = np.array(test_32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_32 = []\n",
    "\n",
    "for i in range(len(test_32)):\n",
    "    pred_32 = model.predict(np.expand_dims(test_32[i], axis=0))\n",
    "    \n",
    "    if pred_32[0][0]>pred_32[0][1] and pred_32[0][0]>pred_32[0][2]:\n",
    "        preds_32.append(0)\n",
    "    elif pred_32[0][1]>pred_32[0][0] and pred_32[0][1]>pred_32[0][2]:\n",
    "        preds_32.append(1)\n",
    "    else:\n",
    "        preds_32.append(2)\n",
    "\n",
    "for i in range(len(test_32)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.subplot(9,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if preds_32[i] == 0:\n",
    "        plt.xlabel('Beisbol')\n",
    "        plt.imshow(test_32[i])\n",
    "    elif preds_32[i] == 1:\n",
    "        plt.xlabel('Cricket')\n",
    "        plt.imshow(test_32[i])\n",
    "    else:\n",
    "        plt.xlabel('Football')\n",
    "        plt.imshow(test_32[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "kernel_size = 4 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 3))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 3))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\", f1_m, recall_m, precision_m])\n",
    "history_3 = model.fit(\n",
    "    X_train, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=11, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])\n",
    "\n",
    "pd.DataFrame(history_3.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de2bb1",
   "metadata": {},
   "source": [
    "## Prepare data test to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8561cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "for file in os.listdir('img/test/'):\n",
    "    image = imread('img/test/'+file)\n",
    "    smallimage = cv2.resize(image,(64,64))\n",
    "    test.append(smallimage)\n",
    "\n",
    "test = np.array(test)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8590acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(test)):\n",
    "    pred = model.predict(np.expand_dims(test[i], axis=0))\n",
    "    \n",
    "    if pred[0][0]>pred[0][1] and pred[0][0]>pred[0][2]:\n",
    "        preds.append(0)\n",
    "    elif pred[0][1]>pred[0][0] and pred[0][1]>pred[0][2]:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1359b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.subplot(9,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if preds[i] == 0:\n",
    "        plt.xlabel('Beisbol')\n",
    "        plt.imshow(test[i])\n",
    "    elif preds[i] == 1:\n",
    "        plt.xlabel('Cricket')\n",
    "        plt.imshow(test[i])\n",
    "    else:\n",
    "        plt.xlabel('Football')\n",
    "        plt.imshow(test[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff970a5e",
   "metadata": {},
   "source": [
    "## Convolutional network with 128 x 128 pixels images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_128, X_test_128, y_train_128, y_test_128 = train_test_split(X_128,Y_128, test_size = .2, random_state=42, stratify=Y_128)\n",
    "\n",
    "print(X_train_128.shape); print(X_test_128.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429966be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_128 = np_utils.to_categorical(y_train,3)\n",
    "Y_test_128 = np_utils.to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 128\n",
    "img_cols = 128\n",
    "kernel_size = 4 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(128, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 3))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 3))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, \n",
    "                        (kernel_size, kernel_size), \n",
    "                        padding='valid', \n",
    "                        input_shape=(img_rows, img_cols, 3))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\", f1_m, recall_m, precision_m])\n",
    "history_3 = model.fit(\n",
    "    X_train_128, # Training data\n",
    "    Y_train_128, # Labels of training data\n",
    "    batch_size=16, # Batch size for the optimizer algorithm\n",
    "    epochs=4, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(X_test_128, Y_test_128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])\n",
    "\n",
    "pd.DataFrame(history_3.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_128 = []\n",
    "\n",
    "for file in os.listdir('img/test/'):\n",
    "    image = imread('img/test/'+file)\n",
    "    smallimage = cv2.resize(image,(128,128))\n",
    "    test_128.append(smallimage)\n",
    "\n",
    "test_128 = np.array(test_128)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17dbd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_128 = []\n",
    "preds_128_arr = []\n",
    "\n",
    "for i in range(len(test_128)):\n",
    "    \n",
    "    pred_128 = model.predict(np.expand_dims(test_128[i], axis=0))\n",
    "    preds_128_arr.append(pred_128)\n",
    "    \n",
    "    if pred_128[0][0]>pred_128[0][1] and pred_128[0][0]>pred_128[0][2]:\n",
    "        preds_128.append(0)\n",
    "    elif pred_128[0][1]>pred_128[0][0] and pred_128[0][1]>pred_128[0][2]:\n",
    "        preds_128.append(1)\n",
    "    else:\n",
    "        preds_128.append(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e78a36",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44179ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = VGG16(input_shape=(64,64,3),\n",
    "                  include_top = False,\n",
    "                   weights = 'imagenet'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e71a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train de last layer of or base model with our data\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc', f1_m, recall_m, precision_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77537b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgghist = model.fit(X_train, Y_train,\n",
    "                    batch_size=64,\n",
    "                   epochs = 15)\n",
    "\n",
    "pd.DataFrame(vgghist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb1d02",
   "metadata": {},
   "source": [
    "### First model transfer learning predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl1_preds = []\n",
    "tl1_preds_arr = []\n",
    "for i in range(len(test)):\n",
    "    tlf1_pred = model.predict(np.expand_dims(test[i], axis=0))\n",
    "    tl1_preds_arr.append(tlf1_pred)\n",
    "    #print(pred)\n",
    "    if tlf1_pred[0][0]>tlf1_pred[0][1] and tlf1_pred[0][0]>tlf1_pred[0][2]:\n",
    "        tl1_preds.append(0)\n",
    "    elif tlf1_pred[0][1]>tlf1_pred[0][0] and tlf1_pred[0][1]>tlf1_pred[0][2]:\n",
    "        tl1_preds.append(1)\n",
    "    else:\n",
    "        tl1_preds.append(2)\n",
    "tl1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.subplot(9,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if tl1_preds[i] == 0:\n",
    "        plt.xlabel('Beisbol')\n",
    "        plt.imshow(test[i])\n",
    "    elif tl1_preds[i] == 1:\n",
    "        plt.xlabel('Cricket')\n",
    "        plt.imshow(test[i])\n",
    "    else:\n",
    "        plt.xlabel('Football')\n",
    "        plt.imshow(test[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432bb44",
   "metadata": {},
   "source": [
    "## Test for samples of 128 x 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(input_shape=(128,128,3),\n",
    "                  include_top = False,\n",
    "                   weights = 'imagenet'\n",
    "                  )\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "x = layers.Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc', f1_m, recall_m, precision_m])\n",
    "\n",
    "vgghist = model.fit(X_train_128, Y_train_128,\n",
    "                    batch_size=64,\n",
    "                   epochs = 10)\n",
    "pd.DataFrame(vgghist.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9802d",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08591a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tl_128 = []\n",
    "preds_tl_128_arr = []\n",
    "for i in range(len(test_128)):\n",
    "    pred_128_tf = model.predict(np.expand_dims(test_128[i], axis=0))\n",
    "    preds_tl_128_arr.append(pred_128_tf)\n",
    "    #print(pred)\n",
    "    if pred_128_tf[0][0]>pred_128_tf[0][1] and pred_128_tf[0][0]>pred_128_tf[0][2]:\n",
    "        preds_tl_128.append(0)\n",
    "    elif pred_128_tf[0][1]>pred_128_tf[0][0] and pred_128_tf[0][1]>pred_128_tf[0][2]:\n",
    "        preds_tl_128.append(1)\n",
    "    else:\n",
    "        preds_tl_128.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea99635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(test_128)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.subplot(9,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if preds_tl_128[i] == 0:\n",
    "        plt.xlabel('Beisbol')\n",
    "        plt.imshow(test_128[i])\n",
    "    elif preds_tl_128[i] == 1:\n",
    "        plt.xlabel('Cricket')\n",
    "        plt.imshow(test_128[i])\n",
    "    else:\n",
    "        plt.xlabel('Football')\n",
    "        plt.imshow(test_128[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(preds_tl_128, columns = ['predictions']).to_csv('predictions/predictions_tfl_model_128_x_128.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7910462",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [1,0,2,2,1,1,0,2,2,1,0,0,1,1,2,1,1,2,0,2,0,0,2,0,1,0,1,2,1,0,2,2,0,2,1,2,1,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57147bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_conv_32 = 0\n",
    "preds_conv = 0\n",
    "preds_conv_128 = 0\n",
    "pred_res = 0\n",
    "pred_128_res = 0\n",
    "for i in range(len(preds_tl_128)):\n",
    "    if preds_32[i] == true[i]:\n",
    "        #preds_conv_32 += 1\n",
    "    if preds[i] == true[i]:\n",
    "        #preds_conv += 1\n",
    "    if preds_128[i] == true[i]:\n",
    "        #preds_conv_128 += 1\n",
    "    if tl1_preds[i] == true[i]:\n",
    "        #pred_res += 1\n",
    "    if preds_tl_128[i] == true[i]:\n",
    "        pred_128_res += 1\n",
    "\n",
    "print('Preds convolutional network 32 x 32: ', preds_conv_32,'\\nPreds convolutional network: ', preds_conv,'\\nPreds for conv 128x128: ', preds_conv_128,\n",
    "      '\\nPreds for tfl1 64x64: ', pred_res, '\\nPreds for tfl2 128x128: ', pred_128_res\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for tf 128 x 128\n",
    "confusion_matrix(true, preds_tl_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49774abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IronHack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
